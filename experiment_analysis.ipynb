{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9982ddc3",
   "metadata": {},
   "source": [
    "# Experiment-Analyse: Multi-Agent System\n",
    "\n",
    "Dieses Notebook analysiert die Ergebnisse der CrewAI Multi-Agent Experimente.\n",
    "\n",
    "## Inhalt\n",
    "1. Daten laden\n",
    "2. √úbersicht aller Experimente\n",
    "3. Visualisierungen (Diagramme)\n",
    "4. Statistische Auswertung\n",
    "5. Export f√ºr wissenschaftliche Arbeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c93cf5",
   "metadata": {},
   "source": [
    "## 1. Setup und Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5fd09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken importieren\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Matplotlib Stil\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"‚úÖ Bibliotheken geladen!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bb242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment-Daten laden\n",
    "# Sucht zuerst in \"projekte\", dann in \"experiments\" f√ºr R√ºckw√§rtskompatibilit√§t\n",
    "EXPERIMENTS_DIR = Path(\"projekte\")\n",
    "if not EXPERIMENTS_DIR.exists():\n",
    "    EXPERIMENTS_DIR = Path(\"experiments\")\n",
    "    print(\"‚ö†Ô∏è 'projekte' Ordner nicht gefunden, verwende 'experiments'\")\n",
    "else:\n",
    "    print(f\"üìÅ Verwende Ordner: {EXPERIMENTS_DIR}\")\n",
    "\n",
    "def load_experiment(exp_dir):\n",
    "    \"\"\"L√§dt ein einzelnes Experiment aus dem Ordner.\"\"\"\n",
    "    json_files = list(exp_dir.glob(\"*_full.json\"))\n",
    "    if not json_files:\n",
    "        return None\n",
    "    \n",
    "    with open(json_files[0], \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    return {\n",
    "        \"id\": data[\"config\"][\"experiment_id\"],\n",
    "        \"name\": data[\"config\"][\"experiment_name\"],\n",
    "        \"timestamp\": data[\"config\"][\"timestamp\"],\n",
    "        \"models\": data[\"config\"][\"models\"],"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a042a3c2",
   "metadata": {},
   "source": [
    "## 2. √úbersichtstabelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d6a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame erstellen f√ºr √úbersicht\n",
    "overview_data = []\n",
    "for exp in experiments:\n",
    "    overview_data.append({\n",
    "        \"Experiment\": exp[\"name\"],\n",
    "        \"Timestamp\": exp[\"timestamp\"][:19],\n",
    "        \"Developer Model\": exp[\"models\"].get(\"developer\", \"N/A\"),\n",
    "        \"Dauer (s)\": exp[\"duration\"],\n",
    "        \"Tokens\": exp[\"tokens\"],\n",
    "        \"Erfolgreich\": \"Ja\" if exp[\"success\"] else \"Nein\"\n",
    "    })\n",
    "\n",
    "df_overview = pd.DataFrame(overview_data)\n",
    "df_overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dace5b3",
   "metadata": {},
   "source": [
    "## 3. Visualisierungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233cbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balkendiagramm: Dauer pro Experiment\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "names = [exp[\"name\"] for exp in experiments]\n",
    "durations = [exp[\"duration\"] for exp in experiments]\n",
    "colors = [\"#2ecc71\" if exp[\"success\"] else \"#e74c3c\" for exp in experiments]\n",
    "\n",
    "bars = ax.bar(names, durations, color=colors, edgecolor=\"black\")\n",
    "ax.set_xlabel(\"Experiment\")\n",
    "ax.set_ylabel(\"Dauer (Sekunden)\")\n",
    "ax.set_title(\"Ausf√ºhrungszeit pro Experiment\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Werte auf Balken anzeigen\n",
    "for bar, duration in zip(bars, durations):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "            f\"{duration:.1f}s\", ha=\"center\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"charts/dauer_pro_experiment.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e897812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charts-Ordner erstellen falls nicht vorhanden\n",
    "Path(\"charts\").mkdir(exist_ok=True)\n",
    "\n",
    "# Balkendiagramm: Tokens pro Experiment\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "tokens = [exp[\"tokens\"] for exp in experiments]\n",
    "\n",
    "bars = ax.bar(names, tokens, color=\"#3498db\", edgecolor=\"black\")\n",
    "ax.set_xlabel(\"Experiment\")\n",
    "ax.set_ylabel(\"Gesch√§tzte Tokens\")\n",
    "ax.set_title(\"Token-Nutzung pro Experiment\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "for bar, token in zip(bars, tokens):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50, \n",
    "            f\"{token}\", ha=\"center\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"charts/tokens_pro_experiment.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39780a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dauer pro Agent (gemittelt √ºber alle Experimente)\n",
    "agent_durations = {}\n",
    "agent_tokens = {}\n",
    "\n",
    "for exp in experiments:\n",
    "    for metric in exp[\"agent_metrics\"]:\n",
    "        role = metric[\"agent_role\"]\n",
    "        if role not in agent_durations:\n",
    "            agent_durations[role] = []\n",
    "            agent_tokens[role] = []\n",
    "        agent_durations[role].append(metric[\"duration_seconds\"])\n",
    "        agent_tokens[role].append(metric[\"estimated_output_tokens\"])\n",
    "\n",
    "# Durchschnitte berechnen\n",
    "avg_durations = {role: sum(vals)/len(vals) for role, vals in agent_durations.items()}\n",
    "avg_tokens = {role: sum(vals)/len(vals) for role, vals in agent_tokens.items()}\n",
    "\n",
    "# Visualisierung\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Dauer pro Agent\n",
    "colors = [\"#2ecc71\", \"#3498db\", \"#e74c3c\", \"#9b59b6\"]\n",
    "roles = list(avg_durations.keys())\n",
    "durations = list(avg_durations.values())\n",
    "\n",
    "axes[0].bar(roles, durations, color=colors[:len(roles)], edgecolor=\"black\")\n",
    "axes[0].set_xlabel(\"Agent\")\n",
    "axes[0].set_ylabel(\"√ò Dauer (Sekunden)\")\n",
    "axes[0].set_title(\"Durchschnittliche Dauer pro Agent\")\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Tokens pro Agent\n",
    "tokens = list(avg_tokens.values())\n",
    "axes[1].bar(roles, tokens, color=colors[:len(roles)], edgecolor=\"black\")\n",
    "axes[1].set_xlabel(\"Agent\")\n",
    "axes[1].set_ylabel(\"√ò Tokens\")\n",
    "axes[1].set_title(\"Durchschnittliche Token-Nutzung pro Agent\")\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"charts/agent_vergleich.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca222138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kreisdiagramm: Anteil der Zeit pro Agent\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "total_duration = sum(avg_durations.values())\n",
    "percentages = [d/total_duration*100 for d in avg_durations.values()]\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    percentages, \n",
    "    labels=roles, \n",
    "    autopct=\"%1.1f%%\",\n",
    "    colors=colors[:len(roles)],\n",
    "    explode=[0.02]*len(roles),\n",
    "    shadow=True\n",
    ")\n",
    "ax.set_title(\"Zeitverteilung nach Agent\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"charts/zeitverteilung_pie.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6645ac70",
   "metadata": {},
   "source": [
    "## 4. Statistische Auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent-Metriken als DataFrame\n",
    "all_metrics = []\n",
    "for exp in experiments:\n",
    "    for metric in exp[\"agent_metrics\"]:\n",
    "        all_metrics.append({\n",
    "            \"Experiment\": exp[\"name\"],\n",
    "            \"Agent\": metric[\"agent_role\"],\n",
    "            \"Modell\": metric[\"model\"],\n",
    "            \"Dauer (s)\": metric[\"duration_seconds\"],\n",
    "            \"Output Tokens\": metric[\"estimated_output_tokens\"],\n",
    "            \"Erfolg\": metric[\"success\"]\n",
    "        })\n",
    "\n",
    "df_metrics = pd.DataFrame(all_metrics)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c927c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiken pro Agent\n",
    "stats = df_metrics.groupby(\"Agent\").agg({\n",
    "    \"Dauer (s)\": [\"mean\", \"std\", \"min\", \"max\"],\n",
    "    \"Output Tokens\": [\"mean\", \"std\", \"min\", \"max\"]\n",
    "}).round(2)\n",
    "\n",
    "print(\"üìä Statistische Auswertung pro Agent:\\n\")\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85201f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gesamtstatistiken\n",
    "print(\"üìä Gesamtstatistiken:\\n\")\n",
    "print(f\"Anzahl Experimente: {len(experiments)}\")\n",
    "print(f\"Erfolgreiche Experimente: {sum(1 for e in experiments if e['success'])}\")\n",
    "print(f\"\")\n",
    "print(f\"Gesamtdauer:\")\n",
    "print(f\"  - Mittelwert: {df_overview['Dauer (s)'].mean():.2f} Sekunden\")\n",
    "print(f\"  - Minimum: {df_overview['Dauer (s)'].min():.2f} Sekunden\")\n",
    "print(f\"  - Maximum: {df_overview['Dauer (s)'].max():.2f} Sekunden\")\n",
    "print(f\"\")\n",
    "print(f\"Token-Nutzung:\")\n",
    "print(f\"  - Mittelwert: {df_overview['Tokens'].mean():.0f} Tokens\")\n",
    "print(f\"  - Minimum: {df_overview['Tokens'].min()} Tokens\")\n",
    "print(f\"  - Maximum: {df_overview['Tokens'].max()} Tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d34cb2",
   "metadata": {},
   "source": [
    "## 5. Export f√ºr wissenschaftliche Arbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504423ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Export\n",
    "df_overview.to_csv(\"export_experimente.csv\", index=False, encoding=\"utf-8\")\n",
    "df_metrics.to_csv(\"export_agent_metriken.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"‚úÖ CSV-Dateien exportiert:\")\n",
    "print(\"   - export_experimente.csv\")\n",
    "print(\"   - export_agent_metriken.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LaTeX Tabelle generieren\n",
    "print(\"üìÑ LaTeX-Tabelle f√ºr wissenschaftliche Arbeit:\\n\")\n",
    "print(r\"\\begin{table}[h]\")\n",
    "print(r\"\\centering\")\n",
    "print(r\"\\caption{√úbersicht der durchgef√ºhrten Experimente}\")\n",
    "print(r\"\\begin{tabular}{|l|c|c|c|}\")\n",
    "print(r\"\\hline\")\n",
    "print(r\"Experiment & Modell & Dauer (s) & Tokens \\\\\")\n",
    "print(r\"\\hline\")\n",
    "for exp in experiments:\n",
    "    model = exp[\"models\"].get(\"developer\", \"N/A\")\n",
    "    print(f\"{exp['name']} & {model} & {exp['duration']:.1f} & {exp['tokens']} \\\\\\\\\")\n",
    "print(r\"\\hline\")\n",
    "print(r\"\\end{tabular}\")\n",
    "print(r\"\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb70e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Systeminfo anzeigen (f√ºr Reproduzierbarkeit)\n",
    "if experiments:\n",
    "    sys_info = experiments[0].get(\"system_info\", {})\n",
    "    print(\"üñ•Ô∏è Systemkonfiguration (f√ºr Reproduzierbarkeit):\\n\")\n",
    "    print(f\"  Platform: {sys_info.get('platform', 'N/A')}\")\n",
    "    print(f\"  Python: {sys_info.get('python_version', 'N/A')}\")\n",
    "    print(f\"  CPU Cores: {sys_info.get('cpu_count', 'N/A')}\")\n",
    "    print(f\"  RAM Total: {sys_info.get('ram_total_gb', 'N/A')} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c83c6",
   "metadata": {},
   "source": [
    "## üìÅ Generierte Dateien\n",
    "\n",
    "Nach Ausf√ºhrung dieses Notebooks findest du:\n",
    "\n",
    "| Datei | Beschreibung |\n",
    "|-------|-------------|\n",
    "| `charts/dauer_pro_experiment.png` | Balkendiagramm: Ausf√ºhrungszeit |\n",
    "| `charts/tokens_pro_experiment.png` | Balkendiagramm: Token-Nutzung |\n",
    "| `charts/agent_vergleich.png` | Vergleich der Agenten |\n",
    "| `charts/zeitverteilung_pie.png` | Kreisdiagramm: Zeitanteile |\n",
    "| `export_experimente.csv` | √úbersicht f√ºr Excel/SPSS |\n",
    "| `export_agent_metriken.csv` | Detaillierte Metriken |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
